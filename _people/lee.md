---
# Your full name (Firstname, lastname)
name: Yoon Lee

# The members are displayed in a hierarchical way, so please choose the role (e.g. Full Professor, Assistant Professor etc) 
# and filter number (e.g. 1, 2, 3) from this list and fill in the role and filter from below:

# (Affiliated) Full Professor - 1
# Associate Professor - 2
# Assistant Professor - 3
# Postdoctoral Researcher - 4
# PhD Candidate - 5
# Research Engineer - 6 
# Guest Researcher - 7
# Secretary - 8
role: PhD Candidate
filter: 5

# same as filter
theme-filter: 5

# choose one or more teams from the following list: delta, kappa, epsilon, lambda, cel
team: [cel]

# provide social URLs (if any)
linkedin: https://www.linkedin.com/in/yoon-lee-144506148/
twitter: 
github: 

# look for your image here: https://github.com/wis-delft/wis-delft.github.io/tree/master/assets/img/people 
# write the exact name of the image as it appears on GitHub
image: Yoon_revised.JPG

# the TUD email address
email: y.lee@tudelft.nl

# Room number (e.g Room - 840 West 4rd floor)
office: 2.E.340

# The name of this file with .html extension (If the filename is andra.md, the "back" field will be andra.html)
back: lee.html

# Go to https://purexml-open.ewi.tudelft.nl 
# choose Query Type = Person, search term = your name, Style = as a list
# generate url and copy the link in the publications_link
publications_link: https://purexml-open.ewi.tudelft.nl/convert/li/persons/64b13370-fd5e-42ee-9c1d-2c86910acd11


---

## About
Her research focus is multimodal attention loop design in the context of Technology-Enhanced Learning (TEL). There are two lines of work in her study; 1) Multimodal machine learning for human attention tracking and 2) Multimodal feedback design using conversational agents. In the process, she tries to design a loop that machines can deeply perceive human behaviors & surroundings and further provide feedback which better supports human attention. She focuses on multimodality as a means to understand and bridge human-machine interactions. Her topic covers Multimodal machine learning and analytics, the Internet of Things (IoT), Instructional design (ID), Interface for conversational agents and robotics, and eye-tracking.