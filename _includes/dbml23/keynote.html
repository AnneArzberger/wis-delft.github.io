<section id="keynote" class="services-section section-colored">
    <div class="container">
        <div class="row text-left margin-top-2">
            <div class="col-md-12 text-center">
                <h2> KEYNOTES </h2>
            </div>

        <div class="col-md-12 margin-top-10" id="keynote-matteo">
                <div class="row pr-4 pl-5">
                    <div class="col-md-2">
                        <img src="{{site.baseurl}}/assets/img/dbml/matteo.jpg"
                             alt="Matteo Interlandi" class="person-image">
                    </div>

                    <div class="col-md-8">
                        <h4 class="padding-bottom-1">How Databases and Machine Learning Systems Can Benefit from Each Other: A Perspective from Product and Research</h4>
                        <h5 class="padding-bottom-1">Matteo Interlandi, Gray System Lab, Microsoft</h5>
                        <p><strong>ABSTRACT.</strong> As machine learning (ML) continues to gain prominence in today's world, 
                            it is becoming increasingly clear that databases and ML systems are two faces of the same coin. 
                            Drawing on my experience in both product and research teams, I will provide three different perspectives 
                            of why I think that databases and machine learning systems are deeply connected. The talk will be 
                            structured around three main topics: execution, optimizations, and abstractions. The audience will 
                            discover how classical machine learning runtimes are closely related to query processing, 
                            and how ML and database operations can be co-optimized. Finally, I will showcase how to turn relational 
                            algebra into the tensor operations. Overall, this talk will demonstrate that databases 
                            and machine learning systems are fundamentally intertwined, and that recognizing this connection 
                            can foster exciting advancements in both fields.</p>

                        <p><strong>ABOUT.</strong> Matteo Interlandi is a Principal Scientist at the Gray Systems Lab (GSL) 
                            within Microsoft. His expertise lies at the intersection of Machine Learning and Database Systems, 
                            and his research has earned him numerous accolades, including a best demo award at VLDB 2022 and an 
                            honorable mention at SIGMOD 2021, and a “Best of VLDB 2016”. Prior to joining Microsoft, Matteo was 
                            a Postdoctoral Scholar at the University of California, Los Angeles, and a Research Associate at the 
                            Qatar Computing Research Institute. Matteo earned his Ph.D. from the University of Modena and Reggio 
                            Emilia, Italy.</p>
                    </div>
                </div>
            </div>

         <!--   <div class="col-md-12 margin-top-10" id="keynote-paul">
                <div class="row pr-4 pl-5">
                    <div class="col-md-2">
                        <img src="{{site.baseurl}}/assets/img/dbml/paul_groth.jpeg"
                             alt="Paul Groth" class="person-image">
                    </div>

                    <div class="col-md-8">
                        <h4 class="padding-bottom-1">Data Curation and Debugging for Data Centric AI</h4>
                        <h5 class="padding-bottom-1">Paul Groth, University of Amsterdam, The Netherlands</h5>
                        <p><strong>ABSTRACT.</strong> It is increasingly recognized that data is a central challenge for
                            AI systems - whether training an entirely new model, discovering data for a model, or
                            applying an existing model to new data. Given this centrality of data, there is need to
                            provide new tools that are able to help data teams create, curate and debug datasets in the
                            context of complex machine learning pipelines. In this talk, I outline the underlying
                            challenges for data debugging and curation in these environments. I then discuss our recent
                            research that both takes advantage of ML to improve datasets but also uses core database
                            techniques for debugging in such complex ML pipelines.</p>
                        <p><strong>ABOUT.</strong> Paul Groth is Professor of Algorithmic Data Science at the University
                            of Amsterdam where he leads the Intelligent Data Engineering Lab (INDElab). He holds a Ph.D.
                            in Computer Science from the University of Southampton (2007) and has done research at the
                            University of Southern California, the Vrije Universiteit Amsterdam and Elsevier Labs. His
                            research focuses on intelligent systems for dealing with large amounts of diverse
                            contextualized knowledge with a particular focus on web and science applications. This
                            includes research in data provenance, data integration and knowledge sharing.
                        </p>
                        <p>
                            Paul is scientific director of the UvA’s Data Science Center. Additionally, he is
                            co-scientific director of two Innovation Center for Artificial Intelligence (ICAI) labs: The
                            AI for Retail (AIR) Lab - a collaboration between UvA and Ahold Delhaize; and the Discovery
                            Lab - a collaboration between Elsevier, the University of Amsterdam and VU University
                            Amsterdam.
                        </p>
                    </div>
                </div>
            </div> -->


            <div class="col-md-12 text-center margin-top-10">
                <h2> INVITED TALKS </h2>
            </div>

             <div class="col-md-12 margin-top-10" id="talk-jyoti">
                <div class="row pr-4 pl-5">
                    <div class="col-md-2">
                        <img src="{{site.baseurl}}/assets/img/dbml/mahmoud.jpg"
                             alt="Mahmoud Abo Khamis" class="person-image">
                    </div>

                    <div class="col-md-8 ">
                        <h4 class="padding-bottom-1">Relational AutoDiff</h4>
                        <h5 class="padding-bottom-1">Mahmoud Abo Khamis, Senior Computer Scientist, RelationalAI</h5>
                        <p><strong>ABSTRACT.</strong> Modern database systems have been progressively expanding their use cases far outside traditional bookkeeping 
                            and data analytics, and into artificial intelligence workloads like machine learning and mathematical optimization. This in turn motivates 
                            the need for native in-database automatic differentiation to better support these use cases.

                            In this talk, we present RelationalAD (RAD), our framework for automatic differentiation at RelationalAI (RAI). 
                            Rel, the modeling language underlying RelationalAI, is declarative and can be viewed as a generalization of Datalog 
                            with infinite relations (e.g. arithmetic), aggregation, and relational abstraction. The input to RAD is a Rel program 
                            that defines a (set of) relational views and the output is another Rel program that defines new views that are the derivatives 
                            with respect to some given input relations. We show that performing AutoDiff inside a high-level database language like Rel 
                            allows us to evaluate derivatives while enjoying many features offered by the underlying database engine like factorization, 
                            query optimization and compilation, as well as support for higher-order derivatives. We present several examples covering 
                            recursive Rel programs, matrix calculus, neural network training, and gradient descent among others. We conclude with some challenges, 
                            design issues, as well as open problems.</p>
                        <p><strong>ABOUT.</strong> Mahmoud Abo Khamis is a Senior Computer Scientist at RelationalAI since 2017. 
                            He received his Ph.D. in Computer Science and Engineering from the State University of New York at Buffalo in 2016. 
                            He also worked as a Senior Database Engineer at Infor from 2015 until 2017. His research interests include database systems and theory, 
                            in-database machine learning, query optimization and evaluation, information theory, and beyond worst-case analysis. 
                            His work has received two PODS Best Paper Awards in 2016 and 2022, two SIGMOD Research Highlight Awards in 2016 and 2022, 
                            and the Best CSE Dissertation Award 2016 from SUNY Buffalo. His work also received several invitations to the Journal of the ACM, 
                            the ACM TODS, and the ACM STOC. He served on the program committees of PODS 2019, PODS 2021, and ICDT 2022, and he is also a reviewer 
                            for the VLDB Journal and the ACM TODS among others.
                        </p>
                    </div>
                </div>
            </div>


           <div class="col-md-12 margin-top-10" id="talk-jie">
                <div class="row pr-4 pl-5">
                    <div class="col-md-2">
                        <img src="{{site.baseurl}}/assets/img/dbml/FengZhang.jpg"
                             alt="FengZhang" class="person-image">
                    </div>

                    <div class="col-md-8">
                        <h4 class="padding-bottom-1">Applying Compressed Data Direct Computing from Database to ML Workloads</h4>
                        <h5 class="padding-bottom-1">Feng Zhang, Associate Professor, Renmin University, China</h5>
                        <p><strong>ABSTRACT.</strong> The rapid growth of data volume poses challenges for modern database systems 
                            in terms of space and time. Compressed data direct computing, as a solution that combines the advantages 
                            of space savings from data compression and efficiency gains from direct computing, has been proved to be 
                            a promising research in the database field. We find that the core of compressed data direct computing is 
                            data reuse, and it can be extended to ML workloads that are also concerned with data size and 
                            computational complexity. In this talk, we introduce Deep Reuse, a concrete implementation of data reuse 
                            into ML workloads. It shows great potential for inference latency reduction on popular neural networks 
                            such as CNNs. Inspired by Deep Reuse, we further carry out research in three aspects: 1) applying it to 
                            optimized operators such as the fast convolution algorithm Winograd, 2) embedding it into neural networks 
                            to address non-determinism and low accuracy problems through a consistent training process, and 
                            3) extending the application to resource-constrained IoT devices.</p>
                        <p><strong>ABOUT.</strong> Feng Zhang is an Associate Professor at Renmin University of China. 
                            He received his PhD from Tsinghua University in 2017, and has been a visiting scholar at NCSU in 2016 
                            and NUS in 2018. His research interests include databases and high-performance computing. 
                            He mainly studies high-performance direct computing on compression in data analytics and management. 
                            His papers are published in prestigious international conferences and journals including SIGMOD, VLDB, 
                            SC, USENIX ATC, ASPLOS, and NeurIPS. He got ACM SIGHPC China Rising Star Award and TPDS Best Paper Award. 
                            He has provided consulting services to numerous IT companies in China, including Alibaba, Tencent, 
                            and Ant Company.</p>
                    </div>
                </div>
            </div>

        </div>
    </div>
</section>